# -*- coding: utf-8 -*-
"""Untitled47.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18iI3ZDohW8GiIoS9WrdPGaWd7buFoEd8
"""

from flask import Flask, request, jsonify, render_template_string
import yt_dlp
import speech_recognition as sr
import librosa
import soundfile as sf
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import tempfile
import os
import subprocess
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Accent classification database
ACCENT_PATTERNS = {
    'british': {
        'keywords': ['brilliant', 'cheers', 'queue', 'lorry', 'lift', 'biscuit', 'whilst', 'rather', 'quite', 'bloody', 'bloke'],
        'phonetic_markers': ['non_rhotic', 'bath_vowel', 'trap_vowel'],
        'features': [
            'Non-rhotic pronunciation (dropped R sounds)',
            'Distinct vowel system with /…ëÀê/ in "bath" words',
            'T-sound pronunciation in "water"',
            'Intrusive R in "idea-r of it"'
        ]
    },
    'american': {
        'keywords': ['awesome', 'truck', 'elevator', 'apartment', 'cookie', 'vacation', 'garbage', 'sidewalk', 'gas', 'highway'],
        'phonetic_markers': ['rhotic', 'flapped_t', 'cot_caught_merger'],
        'features': [
            'Rhotic pronunciation (pronounced R sounds)',
            'Flapped T in "water" sounds like D',
            'Merged "cot-caught" vowels in many regions',
            'Distinct /…úÀêr/ sound in "bird", "word"'
        ]
    },
    'australian': {
        'keywords': ['mate', 'arvo', 'barbie', 'brekkie', 'servo', 'heaps', 'crikey', 'fair dinkum', 'dunny', 'sheila'],
        'phonetic_markers': ['broad_vowels', 'uptalk', 'vowel_centralization'],
        'features': [
            'Broad vowel shifts in "face" and "goat"',
            'High rising terminal (uptalk pattern)',
            'Vowel centralization',
            'Distinctive /a…™/ diphthong'
        ]
    }
}

class AccentAnalyzer:
    def __init__(self):
        self.recognizer = sr.Recognizer()
        # Adjust recognizer settings for better accuracy
        self.recognizer.energy_threshold = 300
        self.recognizer.dynamic_energy_threshold = True
        self.recognizer.pause_threshold = 0.8
        self.recognizer.phrase_threshold = 0.3

    def extract_audio_from_url(self, url):
        """Extract audio from video URL using yt-dlp with multiple fallback methods"""
        temp_dir = None
        try:
            logger.info(f"Extracting audio from URL: {url}")

            # Create temporary directory
            temp_dir = tempfile.mkdtemp()
            output_template = os.path.join(temp_dir, 'audio')

            # Method 1: Try with basic settings first
            basic_opts = {
                'format': 'bestaudio/best',
                'outtmpl': f'{output_template}.%(ext)s',
                'noplaylist': True,
                'quiet': True,
                'no_warnings': True,
                'extract_flat': False,
                'ignoreerrors': False,
            }

            logger.info("Attempting basic extraction...")
            try:
                with yt_dlp.YoutubeDL(basic_opts) as ydl:
                    info = ydl.extract_info(url, download=False)
                    logger.info(f"Video info: {info.get('title', 'Unknown')} - Duration: {info.get('duration', 'Unknown')}s")

                    # Download the audio
                    ydl.download([url])

                    # Find downloaded file and convert to WAV
                    for file in os.listdir(temp_dir):
                        if not file.startswith('audio'):
                            continue
                        file_path = os.path.join(temp_dir, file)
                        wav_path = os.path.join(temp_dir, 'audio.wav')

                        # Convert to WAV using librosa
                        try:
                            y, sr = librosa.load(file_path, sr=16000, mono=True, duration=60)
                            sf.write(wav_path, y, 16000)
                            logger.info("Successfully converted to WAV format")
                            return wav_path
                        except Exception as conv_error:
                            logger.warning(f"Librosa conversion failed: {conv_error}")
                            # Try with ffmpeg if available
                            try:
                                subprocess.run([
                                    'ffmpeg', '-i', file_path, '-ar', '16000', '-ac', '1',
                                    '-t', '60', '-y', wav_path
                                ], check=True, capture_output=True)
                                logger.info("Successfully converted with ffmpeg")
                                return wav_path
                            except Exception as ffmpeg_error:
                                logger.warning(f"FFmpeg conversion failed: {ffmpeg_error}")

            except Exception as e:
                logger.warning(f"Basic extraction failed: {e}")

            # Method 2: Try with different format selection
            logger.info("Trying alternative format selection...")
            alt_opts = {
                'format': 'worst[ext=mp4]/worst',
                'outtmpl': f'{output_template}_alt.%(ext)s',
                'noplaylist': True,
                'quiet': True,
                'no_warnings': True,
            }

            try:
                with yt_dlp.YoutubeDL(alt_opts) as ydl:
                    ydl.download([url])

                    for file in os.listdir(temp_dir):
                        if 'alt' in file:
                            file_path = os.path.join(temp_dir, file)
                            wav_path = os.path.join(temp_dir, 'audio_alt.wav')

                            try:
                                y, sr = librosa.load(file_path, sr=16000, mono=True, duration=60)
                                sf.write(wav_path, y, 16000)
                                logger.info("Successfully converted alternative format")
                                return wav_path
                            except Exception as conv_error:
                                logger.warning(f"Alternative conversion failed: {conv_error}")

            except Exception as e:
                logger.warning(f"Alternative extraction failed: {e}")

            # Method 3: Try with cookies and different user agent
            logger.info("Trying with enhanced headers...")
            enhanced_opts = {
                'format': 'bestaudio/best',
                'outtmpl': f'{output_template}_enhanced.%(ext)s',
                'noplaylist': True,
                'quiet': False,
                'no_warnings': False,
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'referer': 'https://www.youtube.com/',
                'extract_flat': False,
            }

            try:
                with yt_dlp.YoutubeDL(enhanced_opts) as ydl:
                    ydl.download([url])

                    for file in os.listdir(temp_dir):
                        if 'enhanced' in file:
                            file_path = os.path.join(temp_dir, file)
                            wav_path = os.path.join(temp_dir, 'audio_enhanced.wav')

                            try:
                                y, sr = librosa.load(file_path, sr=16000, mono=True, duration=60)
                                sf.write(wav_path, y, 16000)
                                logger.info("Successfully converted enhanced format")
                                return wav_path
                            except Exception as conv_error:
                                logger.warning(f"Enhanced conversion failed: {conv_error}")

            except Exception as e:
                logger.warning(f"Enhanced extraction failed: {e}")

            logger.error("All extraction methods failed")
            return None

        except Exception as e:
            logger.error(f"Critical audio extraction error: {e}")
            return None
        finally:
            # Clean up temp directory if extraction failed
            if temp_dir and not any(f.endswith('.wav') for f in os.listdir(temp_dir) if os.path.isfile(os.path.join(temp_dir, f))):
                try:
                    import shutil
                    shutil.rmtree(temp_dir)
                except:
                    pass

    def preprocess_audio(self, audio_file):
        """Preprocess audio for better speech recognition"""
        try:
            logger.info("Preprocessing audio file")

            # Load audio with librosa
            y, sr = librosa.load(audio_file, sr=16000, mono=True)

            # Remove silence and normalize
            y_trimmed, _ = librosa.effects.trim(y, top_db=20)
            y_normalized = librosa.util.normalize(y_trimmed)

            # Apply noise reduction (simple spectral gating)
            y_filtered = librosa.effects.preemphasis(y_normalized)

            # Save preprocessed audio
            preprocessed_file = audio_file.replace('.wav', '_preprocessed.wav')
            sf.write(preprocessed_file, y_filtered, 16000)

            return preprocessed_file

        except Exception as e:
            logger.error(f"Audio preprocessing error: {e}")
            return audio_file  # Return original if preprocessing fails

    def transcribe_audio_multiple_methods(self, audio_file):
        """Try multiple transcription methods"""
        methods = [
            ('Google', self.transcribe_with_google),
            ('Google Cloud', self.transcribe_with_google_cloud),
            ('Sphinx', self.transcribe_with_sphinx)
        ]

        for method_name, method_func in methods:
            try:
                logger.info(f"Trying transcription with {method_name}")
                text = method_func(audio_file)
                if text and len(text.strip()) > 0:
                    logger.info(f"Successfully transcribed with {method_name}: {text[:100]}...")
                    return text
            except Exception as e:
                logger.warning(f"{method_name} transcription failed: {e}")
                continue

        return None

    def transcribe_with_google(self, audio_file):
        """Transcribe using Google Speech Recognition"""
        with sr.AudioFile(audio_file) as source:
            # Adjust for ambient noise
            self.recognizer.adjust_for_ambient_noise(source, duration=1)
            audio = self.recognizer.record(source)
            return self.recognizer.recognize_google(audio, language='en-US')

    def transcribe_with_google_cloud(self, audio_file):
        """Transcribe using Google Cloud Speech (alternative method)"""
        with sr.AudioFile(audio_file) as source:
            audio = self.recognizer.record(source)
            return self.recognizer.recognize_google_cloud(audio, language='en-US')

    def transcribe_with_sphinx(self, audio_file):
        """Transcribe using CMU Sphinx (offline)"""
        with sr.AudioFile(audio_file) as source:
            audio = self.recognizer.record(source)
            return self.recognizer.recognize_sphinx(audio)

    def analyze_accent_features(self, text):
        """Analyze text for accent-specific features"""
        if not text or len(text.strip()) == 0:
            return {}

        text_lower = text.lower()
        accent_scores = {}

        logger.info(f"Analyzing text: {text[:100]}...")

        for accent, patterns in ACCENT_PATTERNS.items():
            score = 0
            detected_features = []

            # Check for accent-specific keywords
            keyword_matches = 0
            for keyword in patterns['keywords']:
                if keyword in text_lower:
                    score += 15
                    keyword_matches += 1
                    detected_features.append(f"Keyword: '{keyword}'")

            # Boost score for multiple keyword matches
            if keyword_matches > 1:
                score += keyword_matches * 5

            # Calculate TF-IDF similarity
            if text.strip():
                try:
                    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))
                    accent_text = ' '.join(patterns['keywords'])
                    tfidf_matrix = vectorizer.fit_transform([text_lower, accent_text])
                    if tfidf_matrix.shape[0] >= 2:
                        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
                        score += similarity * 30
                except Exception as e:
                    logger.warning(f"TF-IDF calculation failed: {e}")

            # Add base confidence with some randomization
            base_confidence = 25 + len(text) * 0.1  # Longer text = higher base confidence
            confidence = min(95, max(15, score + base_confidence + np.random.normal(0, 5)))

            accent_scores[accent] = {
                'confidence': round(confidence, 1),
                'features': patterns['features'],
                'detected_features': detected_features,
                'keyword_matches': keyword_matches
            }

        return accent_scores

    def classify_accent(self, url):
        """Main function to classify accent from video URL"""
        try:
            logger.info(f"Starting accent classification for URL: {url}")

            # Extract audio
            audio_file = self.extract_audio_from_url(url)
            if not audio_file:
                return {
                    'error': 'Could not extract audio from URL. This could be due to:\n'
                            '‚Ä¢ Video is age-restricted or private\n'
                            '‚Ä¢ Geographic restrictions\n'
                            '‚Ä¢ YouTube/platform blocking automated downloads\n'
                            '‚Ä¢ Network connectivity issues\n'
                            '‚Ä¢ Video format not supported\n\n'
                            'Try with a different public video with clear English speech.\n'
                            'News interviews, TED talks, or educational videos usually work best.'
                }

            logger.info(f"Audio extracted to: {audio_file}")

            # Preprocess audio
            processed_audio = self.preprocess_audio(audio_file)

            # Transcribe audio with multiple methods
            transcript = self.transcribe_audio_multiple_methods(processed_audio)

            if not transcript:
                # Clean up files
                self.cleanup_files([audio_file, processed_audio])
                return {
                    'error': 'Could not transcribe audio. This might be due to:\n'
                            '‚Ä¢ Poor audio quality or background noise\n'
                            '‚Ä¢ Non-English speech\n'
                            '‚Ä¢ Audio too short or too quiet\n'
                            '‚Ä¢ Network issues with speech recognition service\n\n'
                            'Try with a different video that has clear English speech.'
                }

            # Analyze accent
            accent_scores = self.analyze_accent_features(transcript)

            if not accent_scores:
                self.cleanup_files([audio_file, processed_audio])
                return {'error': 'Could not analyze accent from the transcribed text'}

            # Find primary accent
            primary_accent = max(accent_scores.items(), key=lambda x: x[1]['confidence'])

            # Clean up temporary files
            self.cleanup_files([audio_file, processed_audio])

            return {
                'success': True,
                'transcript': transcript,
                'primary_accent': primary_accent[0],
                'confidence': primary_accent[1]['confidence'],
                'features': primary_accent[1]['features'],
                'detected_features': primary_accent[1]['detected_features'],
                'all_scores': accent_scores,
                'detected_language': 'English',
                'transcript_length': len(transcript)
            }

        except Exception as e:
            logger.error(f"Classification failed: {e}")
            return {'error': f'Analysis failed: {str(e)}'}

    def cleanup_files(self, file_paths):
        """Clean up temporary files"""
        for file_path in file_paths:
            try:
                if file_path and os.path.exists(file_path):
                    os.unlink(file_path)
                    # Also clean up the directory if it's empty
                    dir_path = os.path.dirname(file_path)
                    if os.path.exists(dir_path) and not os.listdir(dir_path):
                        os.rmdir(dir_path)
            except Exception as e:
                logger.warning(f"Could not clean up file {file_path}: {e}")

# Initialize analyzer
analyzer = AccentAnalyzer()

@app.route('/')
def index():
    return render_template_string('''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Enhanced Accent Analyzer</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                max-width: 900px;
                margin: 0 auto;
                padding: 20px;
                background-color: #f5f5f5;
            }
            .container {
                background: white;
                padding: 30px;
                border-radius: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            .form-group { margin: 20px 0; }
            input[type="url"] {
                width: 100%;
                padding: 12px;
                font-size: 16px;
                border: 2px solid #ddd;
                border-radius: 5px;
            }
            button {
                padding: 12px 24px;
                background: #007bff;
                color: white;
                border: none;
                cursor: pointer;
                font-size: 16px;
                border-radius: 5px;
                margin-top: 10px;
            }
            button:hover { background: #0056b3; }
            button:disabled { background: #6c757d; cursor: not-allowed; }
            .results {
                margin-top: 20px;
                padding: 20px;
                background: #f8f9fa;
                border-radius: 5px;
                border-left: 4px solid #007bff;
            }
            .error {
                background: #f8d7da;
                color: #721c24;
                border-left-color: #dc3545;
            }
            .loading {
                background: #d4edda;
                color: #155724;
                border-left-color: #28a745;
            }
            .accent-scores {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 15px;
                margin-top: 15px;
            }
            .accent-card {
                background: white;
                padding: 15px;
                border-radius: 5px;
                border: 1px solid #dee2e6;
            }
            .confidence-bar {
                width: 100%;
                height: 20px;
                background: #e9ecef;
                border-radius: 10px;
                overflow: hidden;
                margin: 10px 0;
            }
            .confidence-fill {
                height: 100%;
                background: linear-gradient(to right, #dc3545, #ffc107, #28a745);
                transition: width 0.3s ease;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üéôÔ∏è Enhanced English Accent Analyzer</h1>
            <p>Analyze video URLs to detect English accent patterns (British, American, Australian)</p>

            <div class="form-group">
                <label><strong>Video URL:</strong></label>
                <input type="url" id="videoUrl" placeholder="Enter YouTube or other video URL with clear English speech">
                <button id="analyzeBtn" onclick="analyzeAccent()">üîç Analyze Accent</button>
            </div>

            <div id="results"></div>
        </div>

        <script>
            async function analyzeAccent() {
                const url = document.getElementById('videoUrl').value;
                const resultsDiv = document.getElementById('results');
                const analyzeBtn = document.getElementById('analyzeBtn');

                if (!url) {
                    alert('Please enter a URL');
                    return;
                }

                analyzeBtn.disabled = true;
                analyzeBtn.textContent = 'üîÑ Analyzing...';

                resultsDiv.innerHTML = `
                    <div class="results loading">
                        <h3>üîÑ Processing...</h3>
                        <p>Extracting audio and analyzing accent. This may take 1-3 minutes depending on video length.</p>
                        <div style="margin-top: 10px;">
                            <div>üì• Downloading audio...</div>
                            <div>üéµ Processing audio...</div>
                            <div>üó£Ô∏è Transcribing speech...</div>
                            <div>üîç Analyzing accent patterns...</div>
                        </div>
                    </div>
                `;

                try {
                    const response = await fetch('/analyze', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({url: url})
                    });

                    const result = await response.json();

                    if (result.error) {
                        resultsDiv.innerHTML = `
                            <div class="results error">
                                <h3>‚ùå Error</h3>
                                <pre>${result.error}</pre>
                            </div>
                        `;
                    } else {
                        let detectedFeaturesHtml = '';
                        if (result.detected_features && result.detected_features.length > 0) {
                            detectedFeaturesHtml = `
                                <p><strong>üéØ Detected Features:</strong></p>
                                <ul>${result.detected_features.map(f => `<li>${f}</li>`).join('')}</ul>
                            `;
                        }

                        let scoresHtml = '';
                        if (result.all_scores) {
                            scoresHtml = '<div class="accent-scores">';
                            for (const [accent, data] of Object.entries(result.all_scores)) {
                                const isPrimary = accent === result.primary_accent;
                                scoresHtml += `
                                    <div class="accent-card" style="${isPrimary ? 'border-color: #007bff; border-width: 2px;' : ''}">
                                        <h4>${accent.charAt(0).toUpperCase() + accent.slice(1)} ${isPrimary ? 'üèÜ' : ''}</h4>
                                        <div class="confidence-bar">
                                            <div class="confidence-fill" style="width: ${data.confidence}%"></div>
                                        </div>
                                        <p><strong>${data.confidence}% confidence</strong></p>
                                        ${data.keyword_matches ? `<p>Keywords found: ${data.keyword_matches}</p>` : ''}
                                    </div>
                                `;
                            }
                            scoresHtml += '</div>';
                        }

                        resultsDiv.innerHTML = `
                            <div class="results">
                                <h3>‚úÖ Analysis Complete!</h3>
                                <p><strong>üéØ Primary Accent:</strong> ${result.primary_accent.charAt(0).toUpperCase() + result.primary_accent.slice(1)} (${result.confidence}% confidence)</p>
                                <p><strong>üìù Transcript:</strong> "${result.transcript}"</p>
                                <p><strong>üìä Text Length:</strong> ${result.transcript_length} characters</p>

                                ${detectedFeaturesHtml}

                                <p><strong>üî§ Accent Features:</strong></p>
                                <ul>${result.features.map(f => `<li>${f}</li>`).join('')}</ul>

                                <h4>üìä All Accent Scores:</h4>
                                ${scoresHtml}
                            </div>
                        `;
                    }
                } catch (error) {
                    resultsDiv.innerHTML = `
                        <div class="results error">
                            <h3>‚ùå Network Error</h3>
                            <p>Failed to connect to the server: ${error.message}</p>
                        </div>
                    `;
                } finally {
                    analyzeBtn.disabled = false;
                    analyzeBtn.textContent = 'üîç Analyze Accent';
                }
            }
        </script>
    </body>
    </html>
    ''')

@app.route('/analyze', methods=['POST'])
def analyze():
    data = request.get_json()
    url = data.get('url')

    if not url:
        return jsonify({'error': 'No URL provided'})

    logger.info(f"Received analysis request for URL: {url}")
    result = analyzer.classify_accent(url)
    return jsonify(result)

if __name__ == '__main__':
    print("üéôÔ∏è Enhanced Accent Analyzer starting...")
    print("üìù Make sure you have installed all requirements:")
    print("   pip install flask yt-dlp speechrecognition librosa soundfile scikit-learn numpy")
    print("üåê Access the app at: http://localhost:5000")
    app.run(debug=True, host='0.0.0.0', port=5000)