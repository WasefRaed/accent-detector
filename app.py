# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19NxMAROWASwU4oCiHFC7q9m7EYdTzFBJ
"""

import streamlit as st
import tempfile
import os
import torch
import requests
from moviepy.editor import VideoFileClip
from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification
import torchaudio

# Load model and processor
MODEL_ID = "Ubicoo/wav2vec2-large-xlsr-53-english-accent-classifier"
@st.cache_resource
def load_model():
    processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)
    model = Wav2Vec2ForSequenceClassification.from_pretrained(MODEL_ID)
    return processor, model

processor, model = load_model()
labels = model.config.id2label

def download_video(url):
    response = requests.get(url, stream=True)
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    with open(temp_file.name, 'wb') as f:
        for chunk in response.iter_content(chunk_size=1024 * 1024):
            f.write(chunk)
    return temp_file.name

def extract_audio(video_path):
    temp_audio_path = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
    video = VideoFileClip(video_path)
    video.audio.write_audiofile(temp_audio_path, codec='pcm_s16le')
    return temp_audio_path

def predict_accent(audio_path):
    speech_array, sampling_rate = torchaudio.load(audio_path)
    if sampling_rate != 16000:
        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)
        speech_array = resampler(speech_array)

    input_values = processor(speech_array.squeeze().numpy(), return_tensors="pt", sampling_rate=16000).input_values
    with torch.no_grad():
        logits = model(input_values).logits
    probs = torch.nn.functional.softmax(logits, dim=-1)[0]
    pred_label_id = torch.argmax(probs).item()
    confidence = round(probs[pred_label_id].item() * 100, 2)
    label = labels[pred_label_id]
    return label, confidence, probs

def generate_summary(label, confidence):
    if confidence > 90:
        return f"The speaker shows a strong {label} English accent."
    elif confidence > 70:
        return f"The speaker likely has a {label} accent, though it's not very strong."
    else:
        return f"The speaker may have a {label} accent, but the confidence is lower due to mixed patterns."

# Streamlit UI
st.title("üéôÔ∏è English Accent Detector")
st.write("Upload or paste a public video URL to detect the speaker's English accent.")

video_url = st.text_input("Enter Public Video URL (MP4, Loom, etc.):")

if st.button("Analyze Accent") and video_url:
    with st.spinner("Downloading video..."):
        try:
            video_file = download_video(video_url)
        except Exception as e:
            st.error(f"Failed to download video: {e}")
            st.stop()

    with st.spinner("Extracting audio..."):
        audio_file = extract_audio(video_file)

    with st.spinner("Predicting accent..."):
        accent, confidence, probs = predict_accent(audio_file)
        summary = generate_summary(accent, confidence)

    st.success("Analysis complete!")
    st.metric("Predicted Accent", accent)
    st.metric("Confidence Score", f"{confidence}%")
    st.write(f"**Summary:** {summary}")

    os.remove(video_file)
    os.remove(audio_file)